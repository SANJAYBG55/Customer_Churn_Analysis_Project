# ðŸ“‚ Project Structure

## Directory Organization

```
customer_churn_analysis/
â”‚
â”œâ”€â”€ data/                           # Data directory
â”‚   â”œâ”€â”€ raw/                        # Original, immutable data
â”‚   â”‚   â””â”€â”€ telco_churn.csv        # Source dataset (7,043 customers, 21 columns)
â”‚   â”œâ”€â”€ processed/                  # Cleaned and transformed data
â”‚   â”‚   â”œâ”€â”€ clean_churn_data.csv   # Stage 1 output (cleaned)
â”‚   â”‚   â”œâ”€â”€ enriched_churn_data.csv # Stage 3 output (with features)
â”‚   â”‚   â”œâ”€â”€ data_quality_report.txt # Data validation report
â”‚   â”‚   â””â”€â”€ feature_dictionary.txt  # Feature definitions
â”‚   â””â”€â”€ database/                   # Database files (optional)
â”‚       â””â”€â”€ (empty - reserved for SQLite files)
â”‚
â”œâ”€â”€ scripts/                        # Analysis scripts
â”‚   â”œâ”€â”€ data_cleaning.py           # Stage 1: Data cleaning & validation
â”‚   â”œâ”€â”€ eda_analysis.py            # Stage 2: Exploratory data analysis
â”‚   â”œâ”€â”€ feature_engineering.py     # Stage 3: Feature creation
â”‚   â”œâ”€â”€ analytical_reasoning.py    # Stage 4: Analysis & recommendations
â”‚   â”œâ”€â”€ centralize_data.py         # Data integration utility
â”‚   â”œâ”€â”€ data_profiling.py          # Data profiling utility
â”‚   â””â”€â”€ dataset_profile.py         # Dataset summary utility
â”‚
â”œâ”€â”€ dashboard/                      # Interactive dashboard
â”‚   â””â”€â”€ churn_dashboard.py         # Streamlit dashboard application
â”‚
â”œâ”€â”€ outputs/                        # Analysis outputs
â”‚   â”œâ”€â”€ reports/                   # Text reports
â”‚   â”‚   â”œâ”€â”€ data_quality_report.txt         # Stage 1: Data quality
â”‚   â”‚   â”œâ”€â”€ eda_findings.txt               # Stage 2: EDA insights
â”‚   â”‚   â”œâ”€â”€ analysis_report.txt            # Stage 4: Full analysis
â”‚   â”‚   â”œâ”€â”€ business_recommendations.txt   # Stage 4: Recommendations
â”‚   â”‚   â”œâ”€â”€ executive_summary.txt          # Stage 4: Executive summary
â”‚   â”‚   â””â”€â”€ segment_comparison.csv         # Stage 4: Segment table
â”‚   â””â”€â”€ visualizations/            # Charts and graphs
â”‚       â”œâ”€â”€ churn_distribution.png
â”‚       â”œâ”€â”€ contract_vs_churn.png
â”‚       â”œâ”€â”€ tenure_distribution.png
â”‚       â”œâ”€â”€ payment_method_analysis.png
â”‚       â”œâ”€â”€ service_adoption.png
â”‚       â””â”€â”€ (15-20 PNG files from EDA)
â”‚
â”œâ”€â”€ docs/                           # Project documentation
â”‚   â””â”€â”€ business_context.md        # Business problem definition
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks (optional)
â”‚   â””â”€â”€ (empty - reserved for exploratory notebooks)
â”‚
â”œâ”€â”€ run_full_analysis.py           # Master automation script
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # Project overview
â”œâ”€â”€ USAGE_GUIDE.md                 # Dashboard user guide
â”œâ”€â”€ TECHNICAL_DOCUMENTATION.md     # Technical specifications
â”œâ”€â”€ PROJECT_STRUCTURE.md           # This file
â”œâ”€â”€ DEPLOYMENT.md                  # Deployment instructions
â””â”€â”€ Customer Churn Project.md      # Complete learning guide

```

---

## File Descriptions

### Root Level Files

#### run_full_analysis.py
**Purpose:** Master automation script that runs entire analysis pipeline  
**Usage:** `python run_full_analysis.py`  
**Executes:** All 4 analysis stages in sequence  
**Duration:** 2-3 minutes  
**Output:** All reports and processed datasets

#### requirements.txt
**Purpose:** Python package dependencies  
**Usage:** `pip install -r requirements.txt`  
**Contains:** pandas, numpy, matplotlib, seaborn, plotly, streamlit, scipy

#### README.md
**Purpose:** Main project documentation  
**Audience:** Recruiters, portfolio viewers, GitHub visitors  
**Contains:** Project overview, key findings, quick start, skills demonstrated

#### USAGE_GUIDE.md
**Purpose:** Dashboard user manual  
**Audience:** Business users, stakeholders, managers  
**Contains:** How to navigate dashboard, filter data, export lists, use cases

#### TECHNICAL_DOCUMENTATION.md
**Purpose:** Technical specifications  
**Audience:** Data analysts, developers, technical reviewers  
**Contains:** Architecture, data schemas, methodology, code organization

#### PROJECT_STRUCTURE.md
**Purpose:** Directory organization guide  
**Audience:** Developers, collaborators, new team members  
**Contains:** File structure, descriptions, navigation

#### DEPLOYMENT.md
**Purpose:** Deployment instructions  
**Audience:** DevOps, engineers, anyone deploying to production  
**Contains:** Step-by-step deployment to Streamlit Cloud, Heroku, Docker

#### Customer Churn Project.md
**Purpose:** Complete learning guide (9 stages)  
**Audience:** Learners, students, anyone replicating project  
**Contains:** Full walkthrough, explanations, code, tests

---

### data/ Directory

#### data/raw/
**Purpose:** Original, immutable source data  
**Rule:** NEVER modify files in this folder  
**Contents:** `telco_churn.csv` (7,043 rows, 21 columns)

#### data/processed/
**Purpose:** Cleaned and transformed datasets  
**Contents:**
- `clean_churn_data.csv` - Output of Stage 1 (cleaned data)
- `enriched_churn_data.csv` - Output of Stage 3 (with engineered features)
- `data_quality_report.txt` - Data validation report
- `feature_dictionary.txt` - Feature documentation

#### data/database/
**Purpose:** Reserved for SQLite or other database files  
**Current Status:** Empty (CSV-based project)  
**Future Use:** Production database files

---

### scripts/ Directory

**Purpose:** Modular Python scripts for each analysis stage

#### data_cleaning.py
**Stage:** 1  
**Input:** `data/raw/telco_churn.csv`  
**Output:** `data/processed/clean_churn_data.csv`  
**Functions:**
- Handle missing values
- Convert data types
- Remove duplicates
- Validate data quality

**Usage:** `python scripts/data_cleaning.py`

#### eda_analysis.py
**Stage:** 2  
**Input:** `data/processed/clean_churn_data.csv`  
**Output:** 
- `outputs/reports/eda_findings.txt`
- `outputs/visualizations/*.png` (15-20 charts)

**Functions:**
- Statistical summaries
- Distribution analysis
- Correlation analysis
- Visualization generation
- Hypothesis formation

**Usage:** `python scripts/eda_analysis.py`

#### feature_engineering.py
**Stage:** 3  
**Input:** `data/processed/clean_churn_data.csv`  
**Output:** `data/processed/enriched_churn_data.csv`  
**Functions:**
- Calculate CLV, ARPU
- Create risk scores
- Build segments (Risk, Value, Tenure)
- Compute engagement metrics

**Usage:** `python scripts/feature_engineering.py`

#### analytical_reasoning.py
**Stage:** 4  
**Input:** `data/processed/enriched_churn_data.csv`  
**Output:** 
- `outputs/reports/analysis_report.txt`
- `outputs/reports/business_recommendations.txt`
- `outputs/reports/executive_summary.txt`
- `outputs/reports/segment_comparison.csv`

**Functions:**
- Validate hypotheses
- Analyze segments
- Quantify churn drivers
- Generate recommendations

**Usage:** `python scripts/analytical_reasoning.py`

#### Supporting Scripts

**centralize_data.py**
- Utility for data integration (if multiple sources)
- Not required for single-CSV project

**data_profiling.py**
- Quick data profiling utility
- Generates summary statistics

**dataset_profile.py**
- Dataset overview generator
- Alternative to EDA for quick insights

---

### dashboard/ Directory

#### churn_dashboard.py
**Purpose:** Interactive Streamlit dashboard application  
**Pages:** 5 (Executive Overview, Segment Analysis, Churn Drivers, Recommendations, Customer Explorer)  
**Input:** `data/processed/enriched_churn_data.csv`  
**Usage:** `streamlit run dashboard/churn_dashboard.py`  
**Access:** `http://localhost:8501`

**Features:**
- Interactive filtering
- Real-time visualizations
- Data export
- Multi-page navigation

---

### outputs/ Directory

#### outputs/reports/
**Purpose:** Text-based analysis reports

**data_quality_report.txt**
- Data shape, types
- Missing value summary
- Duplicate check
- Quality assessment

**eda_findings.txt**
- Statistical summaries
- Distribution analysis
- Churn rate breakdowns
- Correlation findings
- Hypotheses generated

**analysis_report.txt**
- Hypothesis validation
- Segment profiling
- Churn driver quantification
- Business impact calculations

**business_recommendations.txt**
- 5 detailed recommendations
- Implementation timelines
- Expected outcomes
- Priority rankings

**executive_summary.txt**
- High-level overview
- Top findings
- Top recommendations
- Next steps

**segment_comparison.csv**
- Segment statistics table
- Churn rates by segment
- Customer counts
- Exportable format

#### outputs/visualizations/
**Purpose:** Static charts and graphs (PNG files)

**Generated Charts:**
- Churn distribution
- Contract type vs churn
- Tenure distribution
- Payment method analysis
- Service adoption charts
- Value segment comparison
- Risk segment profiles
- Correlation heatmaps
- (15-20 total PNG files)

---

### docs/ Directory

#### business_context.md
**Purpose:** Business problem definition and context  
**Contains:**
- Industry background
- Business problem
- Project goals
- Success criteria

---

### notebooks/ Directory

**Purpose:** Jupyter notebooks for exploratory work  
**Current Status:** Empty (optional)  
**Use Case:** Ad-hoc analysis, experimentation, prototyping

---

## Navigation Guide

### For Business Users

**Want to see key findings?**
â†’ Read `README.md` or `outputs/reports/executive_summary.txt`

**Want to explore data?**
â†’ Run `streamlit run dashboard/churn_dashboard.py`

**Want to export customer lists?**
â†’ Use dashboard's Customer Explorer page

### For Data Analysts

**Want to understand methodology?**
â†’ Read `TECHNICAL_DOCUMENTATION.md`

**Want to modify analysis?**
â†’ Edit scripts in `scripts/` directory

**Want to see code?**
â†’ Check `scripts/` for modular scripts

**Want to run full pipeline?**
â†’ Execute `python run_full_analysis.py`

### For Developers

**Want to understand structure?**
â†’ Read this file (`PROJECT_STRUCTURE.md`)

**Want to set up environment?**
â†’ Install from `requirements.txt`

**Want to deploy?**
â†’ Follow `DEPLOYMENT.md`

**Want to contribute?**
â†’ Follow structure, add to appropriate directory

### For Learners

**Want to learn process?**
â†’ Follow `Customer Churn Project.md` (9 stages)

**Want to see outputs?**
â†’ Check `outputs/` directory

**Want to replicate?**
â†’ Run `python run_full_analysis.py`

---

## File Size Reference

| File/Directory | Approximate Size | Notes |
|----------------|------------------|-------|
| data/raw/telco_churn.csv | ~1 MB | Original dataset |
| data/processed/*.csv | ~2.5 MB total | Clean + enriched |
| outputs/reports/*.txt | ~100 KB total | Text reports |
| outputs/visualizations/*.png | ~3 MB total | 15-20 charts |
| scripts/*.py | ~200 KB total | Python scripts |
| dashboard/churn_dashboard.py | ~50 KB | Dashboard app |
| **Total Project Size** | **~7-10 MB** | Lightweight |

---

## Adding New Files

### Adding a New Analysis Script

**Location:** `scripts/new_analysis.py`

**Template:**
```python
"""
NEW ANALYSIS SCRIPT
Description of what this script does
"""

import pandas as pd

# Load data
df = pd.read_csv("data/processed/enriched_churn_data.csv")

# Perform analysis
# ...

# Save output
df.to_csv("outputs/new_output.csv", index=False)
print("Analysis complete!")
```

### Adding a New Report

**Location:** `outputs/reports/new_report.txt`

**Generated by:** Analysis script

**Format:** Plain text with clear sections

### Adding a New Visualization

**Location:** `outputs/visualizations/new_chart.png`

**Generated by:** EDA or analysis script

**Format:** PNG (1200x800px recommended)

### Adding Documentation

**Location:** Root level (`.md` file)

**Naming Convention:** UPPERCASE_WITH_UNDERSCORES.md

**Examples:** `CONTRIBUTING.md`, `CHANGELOG.md`

---

## Maintenance Guidelines

### What to Version Control (Git)

âœ… **Include:**
- All Python scripts (`scripts/`, `dashboard/`)
- All documentation (`.md` files)
- `requirements.txt`
- `run_full_analysis.py`
- Sample data (small datasets only)

âŒ **Exclude (.gitignore):**
- Large data files (`data/raw/*.csv` if >10MB)
- Output files (`outputs/`)
- Cache files (`__pycache__/`, `.ipynb_checkpoints/`)
- Environment files (`.env`, `venv/`)

### What to Backup

**Critical:**
- `data/raw/` (source data)
- `scripts/` (all analysis code)
- Documentation files

**Optional:**
- `outputs/` (can be regenerated)
- `data/processed/` (can be regenerated)

### Cleaning Up

**Safe to Delete:**
- `outputs/` (regenerate with scripts)
- `data/processed/` (regenerate with pipeline)
- `__pycache__/` (Python cache)

**Never Delete:**
- `data/raw/` (source data)
- `scripts/` (analysis code)
- `dashboard/` (dashboard code)
- Documentation files

---

## Troubleshooting

### "File Not Found" Error

**Check:**
1. Are you in project root directory?
2. Did you run previous stages?
3. Are file paths correct?

**Solution:**
```bash
cd path/to/customer_churn_analysis
python run_full_analysis.py
```

### "Module Not Found" Error

**Check:** Dependencies installed?

**Solution:**
```bash
pip install -r requirements.txt
```

### Missing Output Files

**Check:** Did analysis scripts complete successfully?

**Solution:**
```bash
python run_full_analysis.py
```

---

**Last Updated:** January 2026
